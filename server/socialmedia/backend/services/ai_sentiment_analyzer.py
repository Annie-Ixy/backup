# -*- coding: utf-8 -*-
"""
AIæƒ…æ„Ÿåˆ†ææœåŠ¡
ä½¿ç”¨OpenAI GPT-4è¿›è¡Œæ·±åº¦æƒ…æ„Ÿåˆ†æå’Œèˆ†æƒ…æ€»ç»“
"""

import os
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logger = logging.getLogger(__name__)

class AISentimentAnalyzer:
    """AIæƒ…æ„Ÿåˆ†æå™¨ - ä½¿ç”¨å•ä¾‹æ¨¡å¼é¿å…é‡å¤åˆå§‹åŒ–"""
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(AISentimentAnalyzer, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡åˆ›å»ºå®ä¾‹æ—¶æ‰§è¡Œï¼‰"""
        if self._initialized:
            return
            
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.model = os.getenv('OPENAI_MODEL', 'gpt-4')
        self.max_tokens = int(os.getenv('OPENAI_MAX_TOKENS', 2000))
        self.temperature = float(os.getenv('OPENAI_TEMPERATURE', 0.3))
        
        if not self.api_key:
            logger.warning("OpenAI APIå¯†é’¥æœªé…ç½®ï¼ŒAIåˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")
            self.client = None
        else:
            self.client = OpenAI(api_key=self.api_key)
            logger.info("OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        AISentimentAnalyzer._initialized = True
    
    def is_available(self) -> bool:
        """æ£€æŸ¥AIåˆ†ææœåŠ¡æ˜¯å¦å¯ç”¨"""
        return self.client is not None
    
    def analyze_extreme_negative(self, text: str, ai_sentiment: str) -> bool:
        """
        æ£€æµ‹æ˜¯å¦ä¸ºæç«¯è´Ÿé¢è¯„è®º
        
        Args:
            text: è¯„è®ºæ–‡æœ¬
            ai_sentiment: AIæƒ…æ„Ÿåˆ†æç»“æœ
            
        Returns:
            æ˜¯å¦ä¸ºæç«¯è´Ÿé¢è¯„è®º
        """
        try:
            # åªå¯¹è´Ÿé¢è¯„è®ºè¿›è¡Œæç«¯è´Ÿé¢æ£€æµ‹
            if ai_sentiment != 'negative':
                return False
            
            # 1. åŸºç¡€è§„åˆ™æ£€æµ‹
            rule_based_score = self._rule_based_extreme_detection(text)
            
            # 2. AIæ·±åº¦æ£€æµ‹ï¼ˆä»…å¯¹å¯èƒ½çš„æç«¯è´Ÿé¢è¿›è¡Œï¼‰
            if rule_based_score > 0.3 and self.is_available():  # é˜ˆå€¼è¿‡æ»¤
                ai_extreme_score = self._ai_extreme_detection(text)
                final_score = (rule_based_score + ai_extreme_score) / 2
                return final_score >= 0.6  # è°ƒæ•´é˜ˆå€¼ï¼šé™ä½è‡³0.6ä»¥æ›´å¥½åœ°è¯†åˆ«æç«¯è´Ÿé¢
            
            # å¦‚æœAIä¸å¯ç”¨ï¼Œä»…ä½¿ç”¨è§„åˆ™æ£€æµ‹
            return rule_based_score >= 0.6  # çº¯è§„åˆ™é˜ˆå€¼ï¼šè°ƒæ•´è‡³0.6ä»¥åŒ¹é…AI+è§„åˆ™çš„åˆ¤æ–­
            
        except Exception as e:
            logger.error(f"æç«¯è´Ÿé¢æ£€æµ‹å¤±è´¥: {e}")
            return False
    
    def _rule_based_extreme_detection(self, text: str) -> float:
        """åŸºäºè§„åˆ™çš„æç«¯è´Ÿé¢æ£€æµ‹"""
        try:
            score = 0.0
            text_lower = text.lower()
            

            # æ£€æµ‹å¤šä¸ªæ„Ÿå¹å·/é—®å·
            exclamation_count = text.count('!') + text.count('?') + text.count('ï¼') + text.count('ï¼Ÿ')
            if exclamation_count >= 2:
                score += 0.1
                logger.debug(f"æ£€æµ‹åˆ°å¤šä¸ªæ„Ÿå¹å·/é—®å·: {exclamation_count}ä¸ª")
            
            # æ£€æµ‹ä¾®è¾±æ€§è¯æ±‡ï¼ˆä¸­è‹±æ–‡ï¼‰
            insult_keywords = [
                # ä¸­æ–‡ä¾®è¾±è¯æ±‡
                'åƒåœ¾', 'å‚»é€¼', 'å‘çˆ¹', 'éª—å­', 'é»‘å¿ƒ', 'æ¶å¿ƒ', 'å‘äºº', 'è‰', 'å¦ˆçš„',
                'ç‹—å±', 'æ“', 'å§æ§½', 'å°¼ç›', 'æ»š', 'æ­»', 'è„‘æ®‹', 'ç™½ç—´', 'å¼±æ™º', 
                'è ¢è´§', 'åºŸç‰©', 'æ¸£æ¸£', 'æ™ºéšœ', 'äºŒé€¼', 'ç…ç¬”', 'å‚»å‰', 'è´±', 
                'ä½çº§', 'æ¶åŠ£', 'ä¸‹æµ', 'æ— è€»', 'å¯è€»', 'ä¸¢äºº', 'ç³Ÿç³•', 'ç ´çƒ‚',
                'æ··è›‹', 'ç‹å…«è›‹', 'ç‹—ä¸œè¥¿', 'ç•œç”Ÿ', 'ç¦½å…½', 'äººæ¸£', 'è´¥ç±»',
                'ç¥ç»ç—…', 'æœ‰ç—…', 'ç¼ºå¾·', 'æ¶æ¯’', 'é˜´é™©', 'å‘é„™', 'é¾Œé¾Š',
                
                # è‹±æ–‡ä¾®è¾±è¯æ±‡
                'shit', 'fuck', 'damn', 'stupid', 'idiot', 'garbage', 'trash', 'scam',
                'asshole', 'bitch', 'bastard', 'crap', 'suck', 'moron', 'jerk',
                'loser', 'pathetic', 'disgusting', 'awful', 'terrible', 'horrible',
                'worthless', 'useless', 'ridiculous', 'absurd', 'nonsense', 'bullshit',
                'dumb', 'retarded', 'crazy', 'insane', 'sick', 'twisted', 'evil'
            ]
            for keyword in insult_keywords:
                if keyword in text_lower:
                    score += 0.3
                    logger.debug(f"æ£€æµ‹åˆ°ä¾®è¾±æ€§è¯æ±‡: {keyword}")
                    break
            
            # æ£€æµ‹å¨èƒæ€§è¯­è¨€
            threat_keywords = [
                # ä¸­æ–‡å¨èƒè¯æ±‡
                'æŠ•è¯‰', 'æ›å…‰', 'ä¸¾æŠ¥', 'èµ·è¯‰', 'æŠ¥è­¦', 'åª’ä½“', 'ç›‘ç®¡', 'å·¥å•†', 'æ³•é™¢',
                'å‘Šå‘', 'æ£€ä¸¾', 'æ­å‘', 'æ­éœ²', 'å‘ŠçŠ¶', 'ä¸Šè¯‰', 'ç”³è¯‰', 'æ§å‘Š',
                'å¾‹å¸ˆ', 'æ³•å¾‹', 'è¯‰è®¼', 'èµ”å¿', 'ç»´æƒ', 'æ‰“å®˜å¸', 'æ³•åº­', 'ä»²è£',
                'æ¶ˆè´¹è€…åä¼š', 'æ¶ˆå', '12315', 'è®°è€…', 'æ–°é—»', 'ç”µè§†å°', 'æŠ¥ç¤¾',
                'ç½‘ç»œ', 'å¾®åš', 'æœ‹å‹åœˆ', 'å…¬å¼€', 'å…¬å¸ƒ', 'ä¼ æ’­', 'æ‰©æ•£', 'è½¬å‘',
                'å°æ€', 'æŠµåˆ¶', 'é»‘åå•', 'æ‹‰é»‘', 'åˆ é™¤', 'å±è”½', 'æŸ¥å°', 'å…³é—­',
                'å¨èƒ', 'æå“', 'è­¦å‘Š', 'åæœ', 'ä¸¥é‡', 'è´Ÿè´£', 'è¿½ç©¶', 'æƒ©ç½š',
                
                # è‹±æ–‡å¨èƒè¯æ±‡
                'sue', 'lawsuit', 'report', 'expose', 'media', 'police', 'court',
                'lawyer', 'legal', 'prosecution', 'complain', 'complaint', 'authority',
                'government', 'department', 'agency', 'investigation', 'expose',
                'publish', 'broadcast', 'journalist', 'reporter', 'news', 'press',
                'social media', 'facebook', 'twitter', 'instagram', 'youtube',
                'boycott', 'blacklist', 'ban', 'block', 'delete', 'remove', 'shut down',
                'threaten', 'warning', 'consequence', 'serious', 'responsible', 'punishment'
            ]
            for keyword in threat_keywords:
                if keyword in text_lower:
                    score += 0.3
                    logger.debug(f"æ£€æµ‹åˆ°å¨èƒæ€§è¯­è¨€: {keyword}")
                    break
            
            # æ£€æµ‹å¼ºçƒˆè´Ÿé¢æƒ…ç»ªè¯æ±‡
            extreme_negative_words = [
                # ä¸­æ–‡æç«¯è´Ÿé¢æƒ…ç»ªè¯æ±‡
                'æ¶åŠ£', 'æ¶å¿ƒ', 'æ„¤æ€’', 'æ°”æ­»', 'å´©æºƒ', 'ç»æœ›', 'æ„¤æ…¨', 'ç—›æ¨', 'åŒæ¶',
                'æš´æ€’', 'ç‹‚æ€’', 'å‘ç–¯', 'æŠ“ç‹‚', 'ç–¯ç‹‚', 'å¤±æœ›', 'æ²®ä¸§', 'éš¾è¿‡',
                'å¿ƒç¢', 'ç—›è‹¦', 'ç…ç†¬', 'æŠ˜ç£¨', 'å—ç½ª', 'æ‚²æƒ¨', 'å‡„æƒ¨', 'æƒ¨ä¸å¿ç¹',
                'æ— è¯­', 'speechless', 'éœ‡æƒŠ', 'æƒŠè®¶', 'ä¸æ•¢ç›¸ä¿¡', 'æ— æ³•æ¥å—',
                'åæ‚”', 'é—æ†¾', 'å¯æƒœ', 'ç™½è´¹', 'æµªè´¹', 'äº', 'æŸå¤±', 'å€’éœ‰',
                'ç³Ÿç³•', 'ç³Ÿé€', 'å®Œè›‹', 'æ¯äº†', 'ç ¸äº†', 'åºŸäº†', 'å®Œäº†', 'æ­»å®šäº†',
                'å—å¤Ÿäº†', 'å¿æ— å¯å¿', 'æé™', 'çˆ†å‘', 'å½»åº•', 'å®Œå…¨', 'å½»åº•å¤±æœ›',
                'å¿ƒå¯’', 'å¿ƒå‡‰', 'å¯’å¿ƒ', 'å¿ƒæ­»', 'æ­»å¿ƒ', 'æ”¾å¼ƒ', 'ç®—äº†', 'ä¸è¦äº†',
                
                # è‹±æ–‡æç«¯è´Ÿé¢æƒ…ç»ªè¯æ±‡
                'terrible', 'horrible', 'awful', 'disgusting', 'furious', 'hate', 'despise',
                'outrageous', 'unacceptable', 'intolerable', 'unbearable', 'devastating',
                'shocking', 'appalling', 'disgusting', 'revolting', 'sickening',
                'frustrated', 'annoyed', 'irritated', 'pissed', 'mad', 'angry', 'rage',
                'disappointed', 'heartbroken', 'devastated', 'crushed', 'destroyed',
                'hopeless', 'desperate', 'miserable', 'suffering', 'painful', 'agony',
                'nightmare', 'disaster', 'catastrophe', 'failure', 'ruined', 'wasted',
                'regret', 'sorry', 'unfortunate', 'unlucky', 'bad luck', 'curse',
                'enough', 'fed up', 'sick of', 'tired of', 'done with', 'give up', 'junk'
            ]
            extreme_count = sum(1 for word in extreme_negative_words if word in text_lower)
            if extreme_count >= 1:
                score += 0.3
                logger.debug(f"æ£€æµ‹åˆ°å¤šä¸ªæç«¯è´Ÿé¢è¯æ±‡: {extreme_count}ä¸ª")
            
            # æ£€æµ‹æœåŠ¡ç›¸å…³è´Ÿé¢è¯æ±‡
            service_negative_words = [
                # ä¸­æ–‡æœåŠ¡è´Ÿé¢è¯æ±‡
                'æœåŠ¡å·®', 'æ€åº¦å·®', 'ä¸è€çƒ¦', 'ä¸ç¤¼è²Œ', 'ç²—é²', 'å‚²æ…¢', 'å†·æ·¡',
                'ä¸ä¸“ä¸š', 'ä¸è´Ÿè´£', 'æ•·è¡', 'æ¨è„±', 'è¸¢çš®çƒ', 'æ‹–å»¶', 'æ•ˆç‡ä½',
                'å›å¤æ…¢', 'ä¸å›å¤', 'è”ç³»ä¸ä¸Š', 'æ‰¾ä¸åˆ°äºº', 'å®¢æœå·®', 'å”®åå·®',
                'ä¸è§£å†³é—®é¢˜', 'è§£å†³ä¸äº†', 'å¤„ç†ä¸å½“', 'æ€åº¦æ¶åŠ£', 'æ¬ºéª—å®¢æˆ·',
                'è™šå‡æ‰¿è¯º', 'è¯´ä¸€å¥—åšä¸€å¥—', 'è¨€è€Œæ— ä¿¡', 'ä¸å®ˆä¿¡ç”¨', 'éª—é’±',
                
                # è‹±æ–‡æœåŠ¡è´Ÿé¢è¯æ±‡
                'poor service', 'bad service', 'terrible service', 'rude', 'unprofessional',
                'unhelpful', 'slow response', 'no response', 'ignore', 'dismissive',
                'arrogant', 'condescending', 'incompetent', 'irresponsible', 'unreliable',
                'misleading', 'deceptive', 'dishonest', 'fraudulent', 'scam', 'cheat'
            ]
            
            # ç»Ÿè®¡æœåŠ¡è´Ÿé¢è¯æ±‡
            service_count = sum(1 for word in service_negative_words if word in text_lower)
            
            if service_count >= 1:
                score += 0.2
                logger.debug(f"æ£€æµ‹åˆ°æœåŠ¡ç›¸å…³è´Ÿé¢è¯æ±‡: {service_count}ä¸ª")
            
            return min(score, 1.0)
            
        except Exception as e:
            logger.error(f"è§„åˆ™æ£€æµ‹å¤±è´¥: {e}")
            return 0.0
    
    def _ai_extreme_detection(self, text: str) -> float:
        """AIæ·±åº¦æç«¯è´Ÿé¢æ£€æµ‹"""
        try:
            if not self.is_available():
                return 0.0
            
            prompt = f"""
åˆ¤æ–­ä»¥ä¸‹è¯„è®ºçš„æç«¯è´Ÿé¢ç¨‹åº¦ï¼ˆè¿”å›0-1çš„æ•°å­—åˆ†æ•°ï¼‰ï¼š

è¯„ä¼°ç»´åº¦ï¼š
1. æ˜¯å¦åŒ…å«ä¸¥é‡ä¾®è¾±æˆ–å¨èƒï¼ˆ0.4åˆ†ï¼‰
2. æ˜¯å¦è¡¨è¾¾æç«¯æ„¤æ€’æˆ–ä»‡æ¨ï¼ˆ0.3åˆ†ï¼‰
3. æ˜¯å¦å¯èƒ½é€ æˆå“ç‰Œä¸¥é‡æŸå®³ï¼ˆ0.3åˆ†ï¼‰

è¯„è®ºï¼š{text}

åªè¿”å›0-1çš„æ•°å­—åˆ†æ•°ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬æƒ…æ„Ÿæç«¯ç¨‹åº¦è¯„ä¼°ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=10,
                temperature=0.1
            )
            
            score_text = response.choices[0].message.content.strip()
            
            # å°è¯•è§£æåˆ†æ•°
            try:
                score = float(score_text)
                return max(0.0, min(1.0, score))  # ç¡®ä¿åœ¨0-1èŒƒå›´å†…
            except ValueError:
                logger.warning(f"AIè¿”å›çš„åˆ†æ•°æ ¼å¼ä¸æ­£ç¡®: {score_text}")
                return 0.0
                
        except Exception as e:
            logger.error(f"AIæç«¯è´Ÿé¢æ£€æµ‹å¤±è´¥: {e}")
            return 0.0
    
    def analyze_single_text(self, text: str) -> Dict[str, Any]:
        """
        å•æ¡æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
        
        Args:
            text: å¾…åˆ†æçš„æ–‡æœ¬
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.is_available():
            logger.error("OpenAIæœåŠ¡ä¸å¯ç”¨")
            return {
                'sentiment': 'neutral',
                'confidence': 0.0,
                'error': 'OpenAIæœåŠ¡ä¸å¯ç”¨'
            }
        
        if not text or len(text.strip()) == 0:
            return {
                'sentiment': 'neutral',
                'confidence': 0.0,
                'error': 'æ–‡æœ¬ä¸ºç©º'
            }
        
        try:
            prompt = f"""
è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼Œåªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼š

æ–‡æœ¬: "{text}"

è¯·è¿”å›ä»¥ä¸‹æ ¼å¼çš„JSON:
{{
    "sentiment": "positive|negative|neutral",
    "confidence": 0.0-1.0çš„æ•°å€¼,
    "reasoning": "åˆ†æreasoning"
}}

å…¶ä¸­sentimentå¿…é¡»æ˜¯ä»¥ä¸‹ä¸‰ä¸ªå€¼ä¹‹ä¸€ï¼š
- positive: ç§¯ææ­£é¢çš„æƒ…æ„Ÿ
- negative: æ¶ˆæè´Ÿé¢çš„æƒ…æ„Ÿ  
- neutral: ä¸­æ€§æƒ…æ„Ÿ

confidenceè¡¨ç¤ºåˆ†æçš„ç½®ä¿¡åº¦ï¼ŒèŒƒå›´0.0-1.0ã€‚
"""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ï¼Œè¯·ä»…è¿”å›JSONæ ¼å¼çš„åˆ†æç»“æœã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=self.temperature
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„ä»£ç å—åŒ…è£¹
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            elif result_text.startswith('```'):
                result_text = result_text.replace('```', '').strip()
            
            # å°è¯•è§£æJSON
            try:
                import json
                result = json.loads(result_text)
                
                # éªŒè¯ç»“æœæ ¼å¼
                sentiment = result.get('sentiment', '').lower()
                if sentiment not in ['positive', 'negative', 'neutral']:
                    sentiment = 'neutral'
                
                confidence = float(result.get('confidence', 0.0))
                confidence = max(0.0, min(1.0, confidence))  # ç¡®ä¿åœ¨0-1èŒƒå›´å†…
                
                return {
                    'sentiment': sentiment,
                    'confidence': confidence,
                    'reasoning': result.get('reasoning', ''),
                    'error': None
                }
                
            except json.JSONDecodeError:
                logger.error(f"æ— æ³•è§£æAIå“åº”: {result_text}")
                return {
                    'sentiment': 'neutral',
                    'confidence': 0.0,
                    'error': f'AIå“åº”æ ¼å¼é”™è¯¯: {result_text}'
                }
                
        except Exception as e:
            logger.error(f"AIæƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return {
                'sentiment': 'neutral',
                'confidence': 0.0,
                'error': str(e)
            }

    def analyze_sentiment_batch(self, texts: List[str], max_batch_size: int = 5) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡æƒ…æ„Ÿåˆ†æ
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            max_batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆé™ä½ä»¥å‡å°‘æˆæœ¬å’Œæé«˜ç¨³å®šæ€§ï¼‰
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        if not self.is_available():
            logger.error("OpenAIæœåŠ¡ä¸å¯ç”¨")
            return [{'sentiment': 'neutral', 'confidence': 0.0, 'error': 'OpenAIæœåŠ¡ä¸å¯ç”¨'} for _ in texts]
        
        results = []
        
        # åˆ†æ‰¹å¤„ç†ï¼Œå¯¹æ¯æ¡æ–‡æœ¬å•ç‹¬åˆ†æä»¥æé«˜å‡†ç¡®æ€§
        for i, text in enumerate(texts):
            logger.info(f"å¤„ç†ç¬¬ {i+1}/{len(texts)} æ¡æ–‡æœ¬")
            result = self.analyze_single_text(text)
            results.append(result)
            
            # ç®€å•çš„APIé™æµï¼Œé¿å…è¿‡å¿«è°ƒç”¨
            import time
            time.sleep(0.5)  # æ¯æ¬¡è°ƒç”¨é—´éš”0.5ç§’
        
        return results
    
    def analyze_texts_for_upload(self, texts: List[str]) -> Dict[str, Any]:
        """
        ä¸“é—¨ç”¨äºæ–‡ä»¶ä¸Šä¼ æ—¶çš„æ‰¹é‡æ–‡æœ¬æƒ…æ„Ÿåˆ†æ
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åŒ…å«åˆ†æç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
        """
        if not self.is_available():
            logger.warning("OpenAIæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡AIæƒ…æ„Ÿåˆ†æ")
            return {
                'results': [{'sentiment': 'neutral', 'confidence': 0.0, 'error': 'OpenAIæœåŠ¡ä¸å¯ç”¨'} for _ in texts],
                'stats': {
                    'total': len(texts),
                    'success': 0,
                    'positive': 0,
                    'negative': 0,
                    'neutral': 0,
                    'failed': len(texts)
                },
                'available': False
            }
        
        logger.info(f"ğŸ¤– å¼€å§‹AIæƒ…æ„Ÿåˆ†æï¼Œå…± {len(texts)} æ¡æ–‡æœ¬")
        print(f"ğŸ¤– å¼€å§‹AIæƒ…æ„Ÿåˆ†æï¼Œå…± {len(texts)} æ¡æ–‡æœ¬")
        
        # æ‰¹é‡åˆ†æ
        results = []
        stats = {
            'total': len(texts),
            'success': 0,
            'positive': 0,
            'negative': 0,
            'neutral': 0,
            'failed': 0
        }
        
        for i, text in enumerate(texts):
            if i % 10 == 0:  # æ¯10æ¡è¾“å‡ºä¸€æ¬¡è¿›åº¦
                logger.info(f"AIåˆ†æè¿›åº¦: {i+1}/{len(texts)}")
                print(f"ğŸ”„ AIåˆ†æè¿›åº¦: {i+1}/{len(texts)}")
            
            result = self.analyze_single_text(text)
            results.append(result)
            
            # ç»Ÿè®¡ç»“æœ
            if result.get('error'):
                stats['failed'] += 1
            else:
                stats['success'] += 1
                sentiment = result.get('sentiment', 'neutral')
                if sentiment in ['positive', 'negative', 'neutral']:
                    stats[sentiment] += 1
                else:
                    stats['neutral'] += 1
            
            # APIé™æµ
            import time
            time.sleep(0.3)  # ç¨å¾®é™ä½é—´éš”æ—¶é—´
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        success_msg = f"ğŸ¤– AIæƒ…æ„Ÿåˆ†æå®Œæˆ: æˆåŠŸ{stats['success']}æ¡ï¼Œæ€»å…±{stats['total']}æ¡ï¼Œå…¶ä¸­positive {stats['positive']}æ¡ï¼Œnegative {stats['negative']}æ¡ï¼Œneutral {stats['neutral']}æ¡"
        logger.info(success_msg)
        print(success_msg)
        
        if stats['failed'] > 0:
            error_msg = f"âš ï¸ AIåˆ†æå¤±è´¥ {stats['failed']} æ¡"
            logger.warning(error_msg)
            print(error_msg)
        
        return {
            'results': results,
            'stats': stats,
            'available': True
        }
    
    def _analyze_batch(self, texts: List[str]) -> List[Dict[str, Any]]:
        """åˆ†æå•ä¸ªæ‰¹æ¬¡"""
        try:
            # æ„å»ºæç¤ºè¯
            prompt = self._build_sentiment_prompt(texts)
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æƒ…æ„Ÿåˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†æç¤¾äº¤åª’ä½“å†…å®¹çš„æƒ…æ„Ÿå€¾å‘ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            # è§£æå“åº”
            analysis_text = response.choices[0].message.content
            return self._parse_sentiment_response(analysis_text, texts)
            
        except Exception as e:
            logger.error(f"æ‰¹é‡æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return [{"sentiment": "unknown", "confidence": 0.0, "keywords": []} for _ in texts]
    
    def _build_sentiment_prompt(self, texts: List[str]) -> str:
        """æ„å»ºæƒ…æ„Ÿåˆ†ææç¤ºè¯"""
        numbered_texts = []
        for i, text in enumerate(texts, 1):
            # é™åˆ¶å•ä¸ªæ–‡æœ¬é•¿åº¦
            truncated_text = text[:200] + "..." if len(text) > 200 else text
            numbered_texts.append(f"{i}. {truncated_text}")
        
        return f"""
è¯·å¯¹ä»¥ä¸‹{len(texts)}æ¡ç¤¾äº¤åª’ä½“è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†æã€‚å¯¹æ¯æ¡è¯„è®ºï¼Œè¯·æä¾›ï¼š
1. æƒ…æ„Ÿå€¾å‘ï¼špositiveï¼ˆæ­£é¢ï¼‰ã€negativeï¼ˆè´Ÿé¢ï¼‰ã€neutralï¼ˆä¸­æ€§ï¼‰
2. ç½®ä¿¡åº¦ï¼š0-1ä¹‹é—´çš„æ•°å€¼
3. å…³é”®æƒ…æ„Ÿè¯æ±‡ï¼šæœ€å¤š3ä¸ª

è¯„è®ºå†…å®¹ï¼š
{chr(10).join(numbered_texts)}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
  "analyses": [
    {{
      "index": 1,
      "sentiment": "positive/negative/neutral",
      "confidence": 0.85,
      "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
      "reason": "ç®€çŸ­åˆ†æåŸå› "
    }}
  ]
}}
"""
    
    def _parse_sentiment_response(self, response_text: str, original_texts: List[str]) -> List[Dict[str, Any]]:
        """è§£ææƒ…æ„Ÿåˆ†æå“åº”"""
        try:
            import json
            # å°è¯•æå–JSONéƒ¨åˆ†
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            
            if start_idx >= 0 and end_idx > start_idx:
                json_text = response_text[start_idx:end_idx]
                data = json.loads(json_text)
                
                results = []
                analyses = data.get('analyses', [])
                
                for i, text in enumerate(original_texts):
                    if i < len(analyses):
                        analysis = analyses[i]
                        results.append({
                            "sentiment": analysis.get("sentiment", "neutral"),
                            "confidence": float(analysis.get("confidence", 0.5)),
                            "keywords": analysis.get("keywords", []),
                            "reason": analysis.get("reason", ""),
                            "original_text": text[:100] + "..." if len(text) > 100 else text
                        })
                    else:
                        results.append({
                            "sentiment": "neutral",
                            "confidence": 0.5,
                            "keywords": [],
                            "reason": "åˆ†æå¤±è´¥",
                            "original_text": text[:100] + "..." if len(text) > 100 else text
                        })
                
                return results
        
        except Exception as e:
            logger.error(f"è§£ææƒ…æ„Ÿåˆ†æå“åº”å¤±è´¥: {e}")
        
        # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›é»˜è®¤ç»“æœ
        return [{"sentiment": "neutral", "confidence": 0.5, "keywords": [], "reason": "è§£æå¤±è´¥"} for _ in original_texts]
    
    def generate_comprehensive_chart_summary(self, sentiment_stats: Dict[str, Any],
                                           chart_data: Dict[str, Any],
                                           sentiment_trends: Dict[str, Any],
                                           channel_sentiment: Dict[str, Any],
                                           hourly_analysis: Dict[str, Any],
                                           sample_comments: Dict[str, List[str]]) -> str:
        """
        ç”ŸæˆåŸºäºå›¾è¡¨æ•°æ®çš„ç»¼åˆåˆ†ææ€»ç»“
        
        Args:
            sentiment_stats: æƒ…æ„Ÿç»Ÿè®¡æ•°æ®
            chart_data: å›¾è¡¨æ•°æ®(é¥¼å›¾ã€è¶‹åŠ¿å›¾ã€æ¸ é“å›¾ã€æ—¶é—´åˆ†å¸ƒå›¾)
            sentiment_trends: æƒ…æ„Ÿè¶‹åŠ¿æ•°æ®
            channel_sentiment: æ¸ é“æƒ…æ„Ÿåˆ†å¸ƒ
            hourly_analysis: 24å°æ—¶æƒ…æ„Ÿåˆ†å¸ƒ
            sample_comments: æ ·æœ¬è¯„è®º
            
        Returns:
            AIç”Ÿæˆçš„ç»¼åˆå›¾è¡¨åˆ†ææŠ¥å‘Š
        """
        if not self.is_available():
            return self._generate_fallback_chart_summary(sentiment_stats, chart_data, sentiment_trends)
        
        try:
            prompt = self._build_comprehensive_chart_prompt(
                sentiment_stats, chart_data, sentiment_trends, 
                channel_sentiment, hourly_analysis, sample_comments
            )
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ å¿…é¡»åªç”¨ä¸è¶…è¿‡3å¥è¯å›ç­”ã€‚ä¸èƒ½æœ‰æ ‡é¢˜ã€åˆ†æ®µã€åˆ—è¡¨ã€‚åªç»™å‡ºæœ€é‡è¦çš„ç»“è®ºã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,  # è¿›ä¸€æ­¥å‡å°‘tokenæ•°
                temperature=0.3
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç»¼åˆå›¾è¡¨åˆ†æå¤±è´¥: {e}")
            return self._generate_fallback_chart_summary(sentiment_stats, chart_data, sentiment_trends)
    
    def generate_sentiment_summary(self, sentiment_stats: Dict[str, Any], 
                                 sample_comments: Dict[str, List[str]],
                                 time_trends: Dict[str, Any] = None,
                                 channel_stats: Dict[str, Any] = None) -> str:
        """
        ç”Ÿæˆæƒ…æ„Ÿåˆ†ææ€»ç»“æŠ¥å‘Š
        
        Args:
            sentiment_stats: æƒ…æ„Ÿç»Ÿè®¡æ•°æ®
            sample_comments: æ ·æœ¬è¯„è®º
            time_trends: æ—¶é—´è¶‹åŠ¿æ•°æ®
            channel_stats: æ¸ é“ç»Ÿè®¡æ•°æ®
            
        Returns:
            AIç”Ÿæˆçš„æ€»ç»“æŠ¥å‘Š
        """
        if not self.is_available():
            return self._generate_fallback_summary(sentiment_stats)
        
        try:
            prompt = self._build_summary_prompt(sentiment_stats, sample_comments, time_trends, channel_stats)
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„èˆ†æƒ…åˆ†æä¸“å®¶ï¼Œæ“…é•¿ç”Ÿæˆæ¸…æ™°ã€å‡†ç¡®çš„èˆ†æƒ…åˆ†ææŠ¥å‘Šã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæƒ…æ„Ÿæ€»ç»“å¤±è´¥: {e}")
            return self._generate_fallback_summary(sentiment_stats)
    
    def _build_summary_prompt(self, sentiment_stats: Dict[str, Any], 
                            sample_comments: Dict[str, List[str]],
                            time_trends: Dict[str, Any] = None,
                            channel_stats: Dict[str, Any] = None) -> str:
        """æ„å»ºæ€»ç»“æŠ¥å‘Šæç¤ºè¯"""
        
        # åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
        total = sentiment_stats.get('total_comments', 0)
        positive_rate = sentiment_stats.get('positive_rate', 0)
        negative_rate = sentiment_stats.get('negative_rate', 0)
        neutral_rate = sentiment_stats.get('neutral_rate', 0)
        
        # æ ·æœ¬è¯„è®º
        positive_samples = sample_comments.get('positive', [])[:3]
        negative_samples = sample_comments.get('negative', [])[:3]
        
        prompt = f"""
è¯·åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„èˆ†æƒ…åˆ†ææŠ¥å‘Šï¼š

## æ•°æ®æ¦‚è§ˆ
- æ€»è¯„è®ºæ•°ï¼š{total}æ¡
- æ­£é¢æƒ…æ„Ÿï¼š{positive_rate:.1f}%
- è´Ÿé¢æƒ…æ„Ÿï¼š{negative_rate:.1f}%
- ä¸­æ€§æƒ…æ„Ÿï¼š{neutral_rate:.1f}%

## æ ·æœ¬è¯„è®º
### æ­£é¢è¯„è®ºæ ·æœ¬ï¼š
{chr(10).join([f"- {comment[:100]}..." for comment in positive_samples]) if positive_samples else "æš‚æ— "}

### è´Ÿé¢è¯„è®ºæ ·æœ¬ï¼š
{chr(10).join([f"- {comment[:100]}..." for comment in negative_samples]) if negative_samples else "æš‚æ— "}

## æ¸ é“åˆ†å¸ƒ
{self._format_channel_stats(channel_stats) if channel_stats else "æš‚æ— æ¸ é“æ•°æ®"}

è¯·ç”Ÿæˆä¸€ä»½åŒ…å«ä»¥ä¸‹å†…å®¹çš„åˆ†ææŠ¥å‘Šï¼š
1. **æ€»ä½“æƒ…æ„Ÿè¶‹åŠ¿**ï¼šç®€è¦æ¦‚è¿°æ•´ä½“æƒ…æ„Ÿåˆ†å¸ƒ
2. **å…³é”®å‘ç°**ï¼šé‡ç‚¹å…³æ³¨çš„é—®é¢˜å’Œäº®ç‚¹
3. **é£é™©æé†’**ï¼šéœ€è¦æ³¨æ„çš„è´Ÿé¢æƒ…æ„Ÿå’Œæ½œåœ¨é£é™©
4. **å»ºè®®æªæ–½**ï¼šåŸºäºåˆ†æç»“æœçš„å…·ä½“å»ºè®®

è¦æ±‚ï¼š
- è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œæ¡ç†æ¸…æ™°
- çªå‡ºé‡ç‚¹æ•°æ®å’Œè¶‹åŠ¿
- æä¾›å¯æ‰§è¡Œçš„å»ºè®®
- æ€»å­—æ•°æ§åˆ¶åœ¨500å­—ä»¥å†…
"""
        return prompt
    
    def _format_channel_stats(self, channel_stats: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ¸ é“ç»Ÿè®¡ä¿¡æ¯"""
        if not channel_stats:
            return "æš‚æ— æ¸ é“æ•°æ®"
        
        lines = []
        for channel, stats in channel_stats.items():
            if isinstance(stats, dict):
                lines.append(f"- {channel}: {sum(stats.values())}æ¡è¯„è®º")
        
        return chr(10).join(lines) if lines else "æš‚æ— æ¸ é“æ•°æ®"
    
    def _generate_fallback_summary(self, sentiment_stats: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤‡ç”¨æ€»ç»“ï¼ˆå½“AIä¸å¯ç”¨æ—¶ï¼‰"""
        total = sentiment_stats.get('total_comments', 0)
        positive_rate = sentiment_stats.get('positive_rate', 0)
        negative_rate = sentiment_stats.get('negative_rate', 0)
        neutral_rate = sentiment_stats.get('neutral_rate', 0)
        
        return f"""
## èˆ†æƒ…åˆ†ææ€»ç»“

### æ€»ä½“æƒ…æ„Ÿåˆ†å¸ƒ
æœ¬æ¬¡åˆ†æå…±å¤„ç† {total} æ¡è¯„è®ºï¼Œæƒ…æ„Ÿåˆ†å¸ƒå¦‚ä¸‹ï¼š
- æ­£é¢æƒ…æ„Ÿï¼š{positive_rate:.1f}%
- è´Ÿé¢æƒ…æ„Ÿï¼š{negative_rate:.1f}%  
- ä¸­æ€§æƒ…æ„Ÿï¼š{neutral_rate:.1f}%

### å…³é”®å‘ç°
{'è´Ÿé¢æƒ…æ„Ÿå æ¯”è¾ƒé«˜ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨' if negative_rate > 40 else 'æƒ…æ„Ÿåˆ†å¸ƒç›¸å¯¹å‡è¡¡'}

### å»ºè®®æªæ–½
- å¯†åˆ‡ç›‘æ§è´Ÿé¢è¯„è®ºï¼ŒåŠæ—¶å“åº”ç”¨æˆ·å…³åˆ‡
- åˆ†æè´Ÿé¢è¯„è®ºçš„å…·ä½“åŸå› ï¼Œåˆ¶å®šæ”¹è¿›æªæ–½
- åŠ å¼ºæ­£é¢å†…å®¹çš„ä¼ æ’­å’Œæ¨å¹¿

*æ³¨ï¼šAIåˆ†ææœåŠ¡å½“å‰ä¸å¯ç”¨ï¼Œä»¥ä¸Šä¸ºåŸºç¡€ç»Ÿè®¡åˆ†æç»“æœ*
"""


    
    def _build_comprehensive_chart_prompt(self, sentiment_stats: Dict[str, Any],
                                         chart_data: Dict[str, Any],
                                         sentiment_trends: Dict[str, Any],
                                         channel_sentiment: Dict[str, Any],
                                         hourly_analysis: Dict[str, Any],
                                         sample_comments: Dict[str, List[str]]) -> str:
        """æ„å»ºç»¼åˆå›¾è¡¨åˆ†ææç¤ºè¯"""
        
        # æå–å…³é”®æ•°æ®
        total = sentiment_stats.get('total_comments', 0)
        positive_rate = sentiment_stats.get('positive_rate', 0)
        negative_rate = sentiment_stats.get('negative_rate', 0)
        neutral_rate = sentiment_stats.get('neutral_rate', 0)
        
        # å›¾è¡¨æ•°æ®åˆ†æ
        pie_data = chart_data.get('pie_data', [])
        trend_data = chart_data.get('trend_data', {})
        channel_data = chart_data.get('channel_data', {})
        hourly_data = chart_data.get('hourly_data', {})
        
        # æ„å»ºç®€åŒ–æç¤ºè¯
        prompt = f"""
æ•°æ®ï¼š{total}æ¡è¯„è®ºï¼Œæ­£é¢{positive_rate:.1f}%ï¼Œè´Ÿé¢{negative_rate:.1f}%ï¼Œä¸­æ€§{neutral_rate:.1f}%ã€‚{self._format_trend_data(trend_data)}ã€‚

ç”¨2-3å¥è¯åˆ†æï¼šæ•´ä½“æƒ…æ„Ÿå€¾å‘å’Œä¸»è¦å‘ç°ï¼Œç»™å‡ºä¸€ä¸ªå»ºè®®ã€‚
"""
        return prompt
    
    def _format_trend_data(self, trend_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–è¶‹åŠ¿æ•°æ®"""
        if not trend_data:
            return "- æš‚æ— è¶‹åŠ¿æ•°æ®"
        
        dates = trend_data.get('dates', [])
        positive = trend_data.get('positive', [])
        negative = trend_data.get('negative', [])
        
        if not dates or len(dates) < 2:
            return "- æ•°æ®ç‚¹ä¸è¶³ï¼Œæ— æ³•åˆ†æè¶‹åŠ¿"
        
        # ç®€å•çš„è¶‹åŠ¿åˆ†æ
        pos_trend = "ä¸Šå‡" if positive[-1] > positive[0] else "ä¸‹é™"
        neg_trend = "ä¸Šå‡" if negative[-1] > negative[0] else "ä¸‹é™"
        
        return f"""- æ—¶é—´è·¨åº¦ï¼š{dates[0]} è‡³ {dates[-1]}
- æ­£é¢æƒ…æ„Ÿè¶‹åŠ¿ï¼š{pos_trend}
- è´Ÿé¢æƒ…æ„Ÿè¶‹åŠ¿ï¼š{neg_trend}"""
    
    def _format_channel_data(self, channel_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ¸ é“æ•°æ®"""
        if not channel_data:
            return "- æš‚æ— æ¸ é“æ•°æ®"
        
        channels = channel_data.get('channels', [])
        if not channels:
            return "- æš‚æ— æ¸ é“æ•°æ®"
        
        return f"- æ¶‰åŠæ¸ é“ï¼š{', '.join(channels[:5])}{'ç­‰' if len(channels) > 5 else ''}"
    
    def _format_hourly_data(self, hourly_data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–å°æ—¶æ•°æ®"""
        if not hourly_data:
            return "- æš‚æ— æ—¶é—´åˆ†å¸ƒæ•°æ®"
        
        hours = hourly_data.get('hours', [])
        positive = hourly_data.get('positive', [])
        
        if not hours or not positive:
            return "- æš‚æ— æ—¶é—´åˆ†å¸ƒæ•°æ®"
        
        # æ‰¾åˆ°æ´»è·ƒæ—¶æ®µ
        max_idx = positive.index(max(positive)) if positive else 0
        peak_hour = hours[max_idx] if max_idx < len(hours) else 0
        
        return f"- æœ€æ´»è·ƒæ—¶æ®µï¼š{peak_hour}:00-{peak_hour+1}:00"
    
    def _generate_fallback_chart_summary(self, sentiment_stats: Dict[str, Any],
                                       chart_data: Dict[str, Any],
                                       sentiment_trends: Dict[str, Any]) -> str:
        """ç”Ÿæˆfallbackå›¾è¡¨ç»¼åˆæ€»ç»“"""
        try:
            total = sentiment_stats.get('total_comments', 0)
            positive_count = sentiment_stats.get('positive_count', 0)
            negative_count = sentiment_stats.get('negative_count', 0)
            neutral_count = sentiment_stats.get('neutral_count', 0)
            
            positive_rate = round((positive_count / total) * 100, 1) if total > 0 else 0
            negative_rate = round((negative_count / total) * 100, 1) if total > 0 else 0
            neutral_rate = round((neutral_count / total) * 100, 1) if total > 0 else 0
            
            # åˆ†æå›¾è¡¨æ•°æ®
            trend_analysis = self._analyze_trend_data(chart_data.get('trend_data', {}))
            channel_analysis = self._analyze_channel_data(chart_data.get('channel_data', {}))
            
            # åˆ¤æ–­ä¸»è¦æƒ…æ„Ÿå€¾å‘
            if positive_rate >= 40:
                sentiment_desc = "æ•´ä½“æƒ…æ„Ÿåå‘ç§¯æ"
            elif negative_rate >= 30:
                sentiment_desc = "éœ€è¦å…³æ³¨è´Ÿé¢åé¦ˆ"
            else:
                sentiment_desc = "æƒ…æ„Ÿåˆ†å¸ƒç›¸å¯¹å¹³è¡¡"
            
            # ç”Ÿæˆç®€æ´æ€»ç»“
            summary = f"""åŸºäº{total}æ¡è¯„è®ºåˆ†æï¼š{sentiment_desc}ï¼ˆæ­£é¢{positive_rate}%ï¼Œè´Ÿé¢{negative_rate}%ï¼Œä¸­æ€§{neutral_rate}%ï¼‰ã€‚{trend_analysis.replace('â€¢ ', '')} å»ºè®®{self._get_strategy_suggestion(negative_rate).lower()}ã€‚"""
            
            return summary
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆfallbackå›¾è¡¨æ€»ç»“å¤±è´¥: {e}")
            return "æ•°æ®åˆ†ææ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚"
    
    def _analyze_trend_data(self, trend_data: Dict[str, Any]) -> str:
        """åˆ†æè¶‹åŠ¿æ•°æ®"""
        if not trend_data or not trend_data.get('dates'):
            return "æƒ…æ„Ÿè¶‹åŠ¿ç¨³å®š"
        
        dates = trend_data.get('dates', [])
        positive = trend_data.get('positive', [])
        negative = trend_data.get('negative', [])
        
        if len(dates) < 2:
            return "æƒ…æ„Ÿè¶‹åŠ¿ç¨³å®š"
        
        # ç®€å•è¶‹åŠ¿åˆ†æ
        pos_change = positive[-1] - positive[0] if len(positive) >= 2 else 0
        neg_change = negative[-1] - negative[0] if len(negative) >= 2 else 0
        
        if pos_change > 0 and neg_change > 0:
            return "æ­£è´Ÿé¢æƒ…æ„Ÿå‡æœ‰ä¸Šå‡"
        elif pos_change > 0:
            return "æ­£é¢æƒ…æ„Ÿå‘ˆä¸Šå‡è¶‹åŠ¿"
        elif neg_change > 0:
            return "è´Ÿé¢æƒ…æ„Ÿæœ‰æ‰€å¢åŠ "
        else:
            return "æƒ…æ„Ÿè¶‹åŠ¿ä¿æŒç¨³å®š"
    
    def _analyze_channel_data(self, channel_data: Dict[str, Any]) -> str:
        """åˆ†ææ¸ é“æ•°æ®"""
        if not channel_data or not channel_data.get('channels'):
            return "â€¢ æ¸ é“æ•°æ®ä¸è¶³ï¼Œå»ºè®®æ”¶é›†æ›´å¤šå¹³å°çš„åé¦ˆ"
        
        channels = channel_data.get('channels', [])
        return f"â€¢ è¦†ç›–{len(channels)}ä¸ªä¸»è¦æ¸ é“ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨è¡¨ç°å·®å¼‚è¾ƒå¤§çš„å¹³å°"
    
    def _determine_sentiment_trend(self, positive_rate: float, negative_rate: float, neutral_rate: float) -> str:
        """åˆ¤æ–­æƒ…æ„Ÿè¶‹åŠ¿"""
        if positive_rate >= 50:
            return "æ•´ä½“åå‘ç§¯æ"
        elif negative_rate >= 50:
            return "éœ€è¦å…³æ³¨è´Ÿé¢æƒ…ç»ª"
        else:
            return "æƒ…æ„Ÿåˆ†å¸ƒè¾ƒä¸ºå¹³è¡¡"
    
    def _get_sentiment_level(self, negative_rate: float) -> str:
        """è·å–æƒ…æ„Ÿæ°´å¹³"""
        if negative_rate >= 40:
            return "è¾ƒé«˜"
        elif negative_rate >= 25:
            return "ä¸­ç­‰"
        else:
            return "è¾ƒä½"
    
    def _get_strategy_suggestion(self, negative_rate: float) -> str:
        """è·å–ç­–ç•¥å»ºè®®"""
        if negative_rate >= 40:
            return "ç«‹å³åˆ¶å®šé’ˆå¯¹æ€§åº”å¯¹æ–¹æ¡ˆ"
        elif negative_rate >= 25:
            return "åŠ å¼ºç”¨æˆ·æ²Ÿé€šå’Œé—®é¢˜è§£å†³"
        else:
            return "ä¿æŒç°æœ‰ç­–ç•¥å¹¶æŒç»­ä¼˜åŒ–"