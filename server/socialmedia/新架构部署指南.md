# 新三层数据架构部署指南

## 📋 架构概述

新的数据架构采用三层设计：
```
ODS（原始数据层） → DWD（数据仓库详细层） → DWD_AI（AI增强层）
```

### 数据流转过程
1. **文件上传** → ODS表（原始数据接收）
2. **ETL处理** → DWD表（去重清洗）
3. **AI分析** → DWD_AI表（情感分析增强）
4. **业务分析** → 基于DWD_AI表的各种分析

## 🚀 部署步骤

### 步骤 1: 创建新表结构

```sql
-- 执行表结构创建脚本
mysql -u your_username -p mkt < create_new_database_tables.sql
```

**验证表创建:**
```sql
SHOW TABLES LIKE '%dash_social%';
SHOW TABLES LIKE 'etl_%';
```

### 步骤 2: 数据迁移

**对于TiDB数据库（推荐）:**
```sql
-- 执行TiDB兼容的数据迁移脚本
mysql -u your_username -p mkt < migrate_existing_data_tidb_compatible.sql
```

**对于MySQL数据库:**
```sql
-- 执行标准MySQL数据迁移脚本
mysql -u your_username -p mkt < migrate_existing_data.sql
```

> **注意**: TiDB不支持 `CREATE TABLE ... AS SELECT` 语法，因此提供了专门的TiDB兼容版本。

**验证迁移结果:**
```sql
-- 检查三层数据统计
SELECT 'ODS' as layer, COUNT(*) as records FROM ods_dash_social_comments
UNION ALL
SELECT 'DWD' as layer, COUNT(*) as records FROM dwd_dash_social_comments  
UNION ALL
SELECT 'DWD_AI' as layer, COUNT(*) as records FROM dwd_dash_social_comments_ai;
```

### 步骤 3: 测试新架构

```bash
# 运行架构测试脚本
cd socialmedia
python test_new_architecture.py
```

### 步骤 4: 启动应用服务

```bash
# 启动后端服务
cd socialmedia/backend
python app.py
```

### 步骤 5: 执行初始ETL处理

```bash
# 使用API执行完整ETL流水线
curl -X POST http://localhost:9002/api/etl/full-pipeline \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 1000}'
```

### 步骤 6: 启动AI分析

```bash
# 处理待分析的数据
curl -X POST http://localhost:9002/api/ai/process-pending \
  -H "Content-Type: application/json" \
  -d '{"batch_size": 100}'
```

## 🔧 新API接口

### ETL相关API

| 接口 | 方法 | 描述 |
|------|------|------|
| `/api/etl/ods-to-dwd` | POST | ODS到DWD处理 |
| `/api/etl/dwd-to-ai` | POST | DWD到AI同步 |
| `/api/etl/full-pipeline` | POST | 完整ETL流水线 |
| `/api/etl/status` | GET | ETL状态查询 |

### AI分析相关API

| 接口 | 方法 | 描述 |
|------|------|------|
| `/api/ai/process-pending` | POST | 处理待AI分析数据 |
| `/api/ai/retry-failed` | POST | 重试失败的AI分析 |
| `/api/ai/statistics` | GET | AI分析统计信息 |
| `/api/ai/cleanup` | POST | 清理旧分析数据 |

### 上传状态跟踪API (新增)

| 接口 | 方法 | 描述 |
|------|------|------|
| `/api/upload/status/<batch_id>` | GET | 查询批次处理状态 |
| `/api/upload/stats` | GET | 获取上传统计信息 |

### 请求示例

**执行ETL流水线:**
```json
POST /api/etl/full-pipeline
{
  "batch_size": 1000
}
```

**执行AI分析:**
```json
POST /api/ai/process-pending
{
  "batch_size": 100
}
```

## 📊 监控和维护

### 1. 数据层监控

```sql
-- 监控各层数据量
SELECT 
    'ODS' as layer,
    COUNT(*) as total_records,
    COUNT(CASE WHEN processed_flag = 0 THEN 1 END) as pending_processing
FROM ods_dash_social_comments

UNION ALL

SELECT 
    'DWD' as layer,
    COUNT(*) as total_records,
    0 as pending_processing
FROM dwd_dash_social_comments

UNION ALL

SELECT 
    'DWD_AI' as layer,
    COUNT(*) as total_records,
    COUNT(CASE WHEN ai_processing_status = 'pending' THEN 1 END) as pending_processing
FROM dwd_dash_social_comments_ai;
```

### 2. AI分析状态监控

```sql
-- 监控AI处理状态
SELECT 
    ai_processing_status,
    COUNT(*) as record_count,
    ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM dwd_dash_social_comments_ai), 2) as percentage
FROM dwd_dash_social_comments_ai
GROUP BY ai_processing_status;
```

### 3. ETL处理监控

```sql
-- 监控ETL处理日志
SELECT 
    process_type,
    status,
    COUNT(*) as batch_count,
    AVG(success_records) as avg_success_records,
    AVG(duration_seconds) as avg_duration_seconds
FROM etl_processing_log
WHERE start_time >= DATE_SUB(NOW(), INTERVAL 7 DAY)
GROUP BY process_type, status;
```

## 🔄 日常运维操作

### 1. 数据上传后的自动处理流程 (新功能)

```bash
# 1. 上传文件（现在会自动触发后续处理）
curl -X POST http://localhost:9002/api/upload \
  -F "file=@your_data_file.xlsx"

# 返回示例：
{
  "success": true,
  "message": "文件上传成功，ETL和AI分析已启动",
  "data": {
    "batch_id": "batch_20241213_143022_a1b2c3d4",
    "processing_status": {
      "ods_upload": "completed",
      "etl_processing": "completed", 
      "ai_analysis": "completed"
    }
  }
}

# 2. 查询处理状态（使用返回的batch_id）
curl http://localhost:9002/api/upload/status/batch_20241213_143022_a1b2c3d4
```

### 2. 处理状态监控

```bash
# 查询指定批次的详细处理状态
curl http://localhost:9002/api/upload/status/{batch_id}

# 查询ETL整体状态
curl http://localhost:9002/api/etl/status

# 查询AI分析统计
curl http://localhost:9002/api/ai/statistics

# 查询上传统计
curl http://localhost:9002/api/upload/stats
```

### 3. 手动触发（如果自动触发失败）

```bash
# 手动执行ETL处理
curl -X POST http://localhost:9002/api/etl/full-pipeline

# 手动执行AI分析
curl -X POST http://localhost:9002/api/ai/process-pending
```

### 2. 定期维护任务

```bash
# 每日ETL处理（可配置定时任务）
curl -X POST http://localhost:9002/api/etl/ods-to-dwd
curl -X POST http://localhost:9002/api/etl/dwd-to-ai

# 每日AI分析（可配置定时任务）
curl -X POST http://localhost:9002/api/ai/process-pending

# 每周数据清理
curl -X POST http://localhost:9002/api/ai/cleanup \
  -H "Content-Type: application/json" \
  -d '{"days": 30}'
```

### 3. 故障排查

**AI分析失败重试:**
```bash
curl -X POST http://localhost:9002/api/ai/retry-failed
```

**查看ETL状态:**
```bash
curl http://localhost:9002/api/etl/status
```

**查看AI统计:**
```bash
curl http://localhost:9002/api/ai/statistics
```

## ⚠️ 注意事项

### 1. 数据一致性
- ODS层不再检测重复数据，重复检测在DWD层进行
- 确保ETL处理的及时性，避免ODS层数据堆积

### 2. AI服务配置
- 确保OpenAI API配置正确
- 处理地区限制问题（代理配置）
- 监控AI分析的成功率和置信度

### 3. 性能优化
- 根据数据量调整批处理大小
- 定期监控数据库性能
- 适当创建索引优化查询性能

### 4. 备份策略
- 定期备份所有三层数据
- 保留ETL处理日志用于问题追踪
- 备份重要的批次处理结果

## 🎯 性能基准

### 建议的批处理大小
- **ODS→DWD**: 1000-5000条/批次
- **DWD→AI**: 500-2000条/批次  
- **AI分析**: 50-200条/批次（取决于AI服务性能）

### 预期处理时间
- **去重处理**: ~1000条/秒
- **AI分析**: ~10-50条/分钟（取决于AI服务）
- **数据查询**: ~ms级响应时间

## 📈 扩展计划

### 近期优化
1. 实时ETL处理
2. AI分析结果缓存
3. 更多AI模型支持
4. 分析结果API优化

### 长期规划
1. 流式数据处理
2. 分布式AI分析
3. 多租户支持
4. 实时监控Dashboard

---

**部署完成后，请运行测试脚本验证所有功能正常工作。**
