# 社交媒体数据处理架构更新指南

## 📋 更新概述

从原来的单层表结构升级为三层数据仓库架构（ODS → DWD → DWD_AI），实现数据接收、处理、分析的分离，提升系统稳定性和可扩展性。

### 主要变更
- **架构升级**：单表 → 三层数据仓库（ODS/DWD/DWD_AI）
- **去重策略**：从ODS层去重 → DWD层ETL去重
- **数据流优化**：原始数据直接存储 → ETL过滤处理 → AI分析增强

## 🚀 部署步骤

### 步骤1：备份现有数据（重要！）
```sql
-- 备份主要数据表
CREATE TABLE ods_dash_social_comments_backup AS 
SELECT * FROM ods_dash_social_comments;

CREATE TABLE dwd_dash_social_comments_backup AS 
SELECT * FROM dwd_dash_social_comments WHERE 1=0; -- 如果表存在

CREATE TABLE etl_processing_log_backup AS 
SELECT * FROM etl_processing_log WHERE 1=0; -- 如果表存在
```

### 步骤2：执行数据库架构更新
```bash
# 在 MySQL/TiDB 中执行新的建表语句
mysql -u your_username -p mkt < create_new_database_tables.sql
```

### 步骤3：清理废弃约束（如果存在）
```sql
-- 删除ODS表中的旧去重约束（如果存在）
-- ALTER TABLE ods_dash_social_comments DROP INDEX uk_duplicate_check;
-- ALTER TABLE ods_dash_social_comments DROP INDEX uk_duplicate_check_v2;

-- 检查约束状态
SHOW INDEX FROM ods_dash_social_comments WHERE Key_name LIKE '%duplicate%';
```

### 步骤4：重启应用服务
```bash
# 停止服务
./stop.sh  # 或 stop.bat (Windows)

# 启动服务
./start.sh  # 或 start.bat (Windows)
```

### 步骤5：验证新架构
```sql
-- 验证所有表是否创建成功
SELECT TABLE_NAME, TABLE_COMMENT, TABLE_ROWS 
FROM INFORMATION_SCHEMA.TABLES 
WHERE TABLE_SCHEMA = 'mkt' 
  AND (TABLE_NAME LIKE '%social%' 
   OR TABLE_NAME LIKE 'etl_%'
   OR TABLE_NAME LIKE '%upload%')
ORDER BY TABLE_NAME;

-- 检查DWD层去重约束
SHOW INDEX FROM dwd_dash_social_comments WHERE Key_name = 'uk_dwd_dedupe';
```

## 🔍 新架构数据流说明

### 三层数据架构
```
原始数据 → ODS（原始数据层）→ ETL处理 → DWD（数据仓库详细层）→ AI分析 → DWD_AI（AI增强层）
```

### 1. ODS层（ods_dash_social_comments）
- **作用**：接收所有原始数据，无任何处理和约束
- **特点**：
  - 允许重复数据
  - text和last_update可为空
  - 直接保存上传的原始内容
  - processed_flag标记是否已被ETL处理

### 2. DWD层（dwd_dash_social_comments）
- **作用**：存储过滤清洗后的去重数据
- **去重规则**：`uk_dwd_dedupe (dedupe_date, brand_label, author_name, channel, text(255))`
- **过滤条件**：
  - text非空
  - last_update有效
- **去重逻辑**：基于日期+品牌+作者+渠道+文本内容，保留时间戳最晚的记录

### 3. DWD_AI层（dwd_dash_social_comments_ai）
- **作用**：存储完整的AI分析结果
- **特点**：
  - 包含基础AI分析结果（情感分析、置信度）
  - 支持扩展AI分析（JSON格式的详细分析）
  - 极端负面评论标识
  - 与DWD层通过外键关联

### 业务场景示例
```
场景1：数据上传
- 用户上传包含重复和无效数据的Excel文件
- 系统直接保存到ODS层，不做任何过滤 ✅ 全部保存

场景2：ETL处理
- text为空的记录 → 过滤掉
- last_update无效的记录 → 过滤掉  
- 重复记录（基于去重规则）→ 保留最新的

场景3：AI分析
- 只处理DWD层中的有效数据
- 分析完成后同步到DWD_AI层
```

## ⚠️ 重要注意事项

### 数据迁移
- **现有ODS数据**：需要运行ETL处理将其迁移到DWD层
- **去重约束清理**：确保删除ODS表中的旧约束（uk_duplicate_check）
- **表名变更**：ETL日志表从 `etl_processing_log` 更名为 `dwd_etl_processing_log`

### 性能优化
- **批处理**：ETL和AI分析都支持批量处理，可调整批次大小
- **索引优化**：新架构包含完整的索引策略，支持复杂查询场景
- **数据过滤**：在ETL阶段过滤无效数据，减少AI分析负载

### 运维监控
- **处理状态跟踪**：通过 `processed_flag` 跟踪ODS数据处理状态
- **ETL日志监控**：`dwd_etl_processing_log` 记录详细的处理统计
- **AI分析状态**：`ai_processing_status` 和 `extreme_negative_processing_status` 跟踪AI处理进度

## 🧪 测试验证

### 测试用例1：ODS层数据接收
```
上传包含以下记录的文件：
1. text="", author_name="test_user", channel="instagram" (text为空)
2. text="测试内容", author_name="", channel="instagram" (author为空)
3. text="正常内容", author_name="test_user", channel="instagram" (正常数据)

预期结果：
- ODS层：3条记录全部插入成功
- ETL处理后DWD层：只有第3条记录进入DWD层
```

### 测试用例2：DWD层去重逻辑
```
ODS层包含以下记录：
1. text="测试内容", author_name="user1", channel="instagram", last_update="2024-01-01 10:00:00"
2. text="测试内容", author_name="user1", channel="instagram", last_update="2024-01-01 11:00:00"
3. text="测试内容", author_name="user1", channel="instagram", last_update="2024-01-01 09:00:00"

预期结果：
- ETL处理后DWD层：只保留第2条记录（时间最晚）
- 去重统计：duplicate_records=2
```

### 测试用例3：跨日期不去重
```
ODS层包含以下记录：
1. text="测试内容", author_name="user1", channel="instagram", last_update="2024-01-01 10:00:00"
2. text="测试内容", author_name="user1", channel="instagram", last_update="2024-01-02 10:00:00"

预期结果：
- ETL处理后DWD层：2条记录都保留（不同日期不去重）
```

## 🔄 回滚方案

如果需要回滚到原来的单表架构：

### 步骤1：数据合并
```sql
-- 将DWD和AI数据合并回ODS表（如果需要保留处理结果）
INSERT INTO ods_dash_social_comments 
SELECT source_record_id, last_update, brand_label, author_name, channel, 
       message_type, text, tags, post_link, sentiment, caption, 
       upload_batch_id, original_row_index, processed_at, created_at, 1
FROM dwd_dash_social_comments;
```

### 步骤2：恢复旧约束
```sql
-- 恢复原有的去重约束
ALTER TABLE ods_dash_social_comments 
ADD UNIQUE KEY uk_duplicate_check (text(255), author_name, channel);
```

### 步骤3：删除新表
```sql
-- 删除新增的表（谨慎操作！）
-- DROP TABLE dwd_dash_social_comments_ai;
-- DROP TABLE dwd_dash_social_comments;
-- DROP TABLE dwd_etl_processing_log;
```

## 📞 技术支持

### 监控检查清单
1. **数据库连接**：确认所有表创建成功
2. **约束状态**：验证ODS层无重复约束，DWD层有去重约束
3. **ETL处理**：检查 `dwd_etl_processing_log` 中的处理统计
4. **数据流通**：验证 ODS → DWD → DWD_AI 的数据传递

### 常见问题排查
- **上传失败**：检查ODS表是否允许重复数据
- **ETL无数据**：确认ODS中有 `processed_flag=0` 的未处理数据
- **AI分析卡住**：检查DWD中的AI处理状态字段
- **性能问题**：调整ETL和AI分析的批处理大小

### 日志查询
```sql
-- 查看最近的ETL处理日志
SELECT batch_id, step_name, status, success_records, failed_records, 
       filtered_empty_text_records, filtered_invalid_date_records, 
       start_time, end_time, error_message
FROM dwd_etl_processing_log 
ORDER BY start_time DESC 
LIMIT 10;

-- 查看数据分布统计
SELECT 
    'ODS' as layer, COUNT(*) as total_records, 
    SUM(CASE WHEN processed_flag = 0 THEN 1 ELSE 0 END) as unprocessed
FROM ods_dash_social_comments
UNION ALL
SELECT 
    'DWD' as layer, COUNT(*) as total_records,
    SUM(CASE WHEN ai_processing_status = 'pending' THEN 1 ELSE 0 END) as pending_ai
FROM dwd_dash_social_comments  
UNION ALL
SELECT 
    'DWD_AI' as layer, COUNT(*) as total_records,
    SUM(CASE WHEN ai_processing_status = 'completed' THEN 1 ELSE 0 END) as completed_ai
FROM dwd_dash_social_comments_ai;
```
